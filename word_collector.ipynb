{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_path = '/media/alex/nvme-a/vosk-model-ru-0.10/graph/words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [line, id]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_csv(words_path, sep=\" \")\n",
    "words.columns = ['line', 'id']\n",
    "words[words.line.str.contains('шолохово')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Форматирование и очистка примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_data(path):\n",
    "    \n",
    "    with open(path, 'rt', encoding=\"utf8\", errors='ignore') as file:\n",
    "        words = file.read()\n",
    "    words = words.lower()\n",
    "    \n",
    "    correct = '\\nйцукенгшщзхъфывапролджэячсмитьбю '\n",
    "    used = ''.join(list(set(words)))\n",
    "    for u in used:\n",
    "        if u not in correct:\n",
    "            words = words.replace(u, ' ')\n",
    "    while '  ' in words:\n",
    "        words = words.replace('  ', ' ')\n",
    "    words = words.replace(' ', '\\n')\n",
    "    \n",
    "    with open(path.replace('.csv','_b.csv'), 'w') as file:\n",
    "        file.write(words)\n",
    "        \n",
    "    words = pd.read_csv(path.replace('.csv','_b.csv'), header=None)\n",
    "    words.columns = ['word']    \n",
    "    words.drop_duplicates(inplace=True)\n",
    "    words = words.dropna()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(words_path):\n",
    "    df = pd.DataFrame(columns = ['word'])\n",
    "    for path in words_path:\n",
    "        df = pd.concat([df, word_data(path)], axis = 0)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df.dropna()\n",
    "    df = pd.DataFrame(df[df.word.str.len()>3])\n",
    "    df.to_csv('csv/all_words.csv', index = False)\n",
    "    missing_words = df[df.word.isin(words.line)==False]\n",
    "    missing_words.to_csv('csv/missing_words.csv', index = False)\n",
    "    print('known words:', len(words))\n",
    "    print('external words:', len(df))\n",
    "    print('unknown words:', len(missing_words))    \n",
    "    return missing_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отсутсвующие слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known words: 709156\n",
      "external words: 5011\n",
      "unknown words: 1710\n"
     ]
    }
   ],
   "source": [
    "# Улицы\n",
    "words_path = ['csv/streets_msk.csv', 'csv/streets_spb.csv', 'csv/streets_reg.csv']\n",
    "missing_words = get_missing(words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слов в модели: 709156\n",
      "слов в 1С: 1016\n",
      "слов, отсутствующих в модели: 40\n"
     ]
    }
   ],
   "source": [
    "# Неисправности\n",
    "words_path = ['csv/neispr_msk.csv', 'csv/neispr_spb.csv', 'csv/neispr_reg.csv']\n",
    "missing_words = get_missing(words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "слов в модели: 709156\n",
      "слов в 1С: 81\n",
      "слов, отсутствующих в модели: 24\n"
     ]
    }
   ],
   "source": [
    "# Бренды\n",
    "words_path = ['csv/brands_msk.csv', 'csv/brands_spb.csv', 'csv/brands_reg.csv']\n",
    "missing_words = get_missing(words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known words: 709156\n",
      "external words: 6076\n",
      "unknown words: 1773\n"
     ]
    }
   ],
   "source": [
    "# Объединение\n",
    "words_path = [\n",
    "    'csv/streets_msk.csv',\n",
    "    'csv/streets_spb.csv',\n",
    "    'csv/streets_reg.csv',\n",
    "    'csv/neispr_msk.csv',\n",
    "    'csv/neispr_spb.csv',\n",
    "    'csv/neispr_reg.csv',\n",
    "    'csv/brands_msk.csv',\n",
    "    'csv/brands_spb.csv',\n",
    "    'csv/brands_reg.csv'\n",
    "]\n",
    "missing_words = get_missing(words_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Склонение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pymorphy2.readthedocs.io/en/0.2/user/index.html\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words = pd.read_csv('csv/missing_words.csv')\n",
    "lexemed_words = []\n",
    "for ids, missing in missing_words.iterrows():\n",
    "    original = morph.parse(missing.word)[0]\n",
    "    for lex in original.lexeme:\n",
    "        lexemed_words.append(lex.word)\n",
    "lexemed = pd.DataFrame(sorted(set(lexemed_words)))\n",
    "lexemed.columns = ['word']\n",
    "lexemed.to_csv('csv/lexemed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known words: 709156\n",
      "external words: 21116\n",
      "unknown words: 19741\n"
     ]
    }
   ],
   "source": [
    "# оставим только отсутствующие в модели слова\n",
    "lexemed_missing = get_missing(['csv/lexemed.csv'])\n",
    "lexemed_missing.to_csv('csv/lexemed_missing.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
